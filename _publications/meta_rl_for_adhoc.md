--- 
title: "Learning to Cooperate with Unseen Agents Through Meta-Reinforcement Learning" 
collection: publications 
permalink: /publication/meta-rl-for-ad-hoc 
excerpt: '' 
date: 2020-12-19
venue: '<i>The 20th International Conference on Autonomous Agents and Multiagent Systems. <b>AAMAS 2021 (Extended abstract)</b></i>' 
paperurl:  
citation: '<b>Rujikorn Charakorn</b>, Poramate Manoonpong, and Nat Dilokthanakul' 
--- 

 
[pdf](http://www.ifaamas.org/Proceedings/aamas2021/pdfs/p1478.pdf), [poster](/files/posters/aamas_poster_update2.pdf), [full paper](https://arxiv.org/pdf/2111.03431.pdf)


### Abstract
Ad hoc teamwork problem describes situations where an agent has to cooperate with previously unseen agents to achieve a common goal. For an agent to be successful in these scenarios, it has to have cooperative skills. One could implement cooperative skills into an agent by using domain knowledge (e.g., goals, roles, and protocols) to design the agent's behaviours. However, in complex domains, domain knowledge might not be available. Therefore, it is interesting to explore how to directly learn cooperative skills from data. In this work, we apply meta-reinforcement learning (meta-RL) formulation in the context of ad hoc teamwork problem. Our experiments show that such a method could produce cooperative agents in two cooperative environments with different cooperative circumstances.


### Citation
```
@inproceedings{charakorn2021learning,
  title={Learning to Cooperate with Unseen Agents Through Meta-Reinforcement Learning},
  author={Charakorn, Rujikorn and Manoonpong, Poramate and Dilokthanakul, Nat},
  booktitle={Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems},
  pages={1478--1479},
  year={2021}
}
```